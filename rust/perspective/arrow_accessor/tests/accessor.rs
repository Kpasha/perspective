/******************************************************************************
 *
 * Copyright (c) 2019, the Perspective Authors.
 *
 * This file is part of the Perspective library, distributed under the terms of
 * the Apache License 2.0.  The full license can be found in the LICENSE file.
 *
 */
use std::collections::HashMap;
use std::sync::Arc;

use arrow::array::*;
use arrow::datatypes::{DataType, DateUnit, Field, Int32Type, Schema, SchemaRef, TimeUnit};
use arrow::record_batch::RecordBatch;
use chrono::{NaiveDate, NaiveDateTime};

use arrow_accessor;

// Load all datatypes generated by Perspective
#[test]
fn load_arrow() {
    let strings = vec!["abc", "def", "abc", "hij", "klm"];
    let dict_array: DictionaryArray<Int32Type> = strings.into_iter().collect();

    let arrays: Vec<ArrayRef> = vec![
        Arc::new(Int32Array::from(vec![1, 2, 3, 4, 5])),
        Arc::new(Int64Array::from(vec![1, 2, 3, 4, 5])),
        Arc::new(Float64Array::from(vec![1.5, 2.5, 3.5, 4.5, 5.5])),
        Arc::new(Date32Array::from(vec![
            18000, 18100, 18200, 18300, 18400,
        ])),
        Arc::new(TimestampMillisecondArray::from(vec![
            NaiveDateTime::parse_from_str("2020-01-15 12:30:45", "%Y-%m-%d %H:%M:%S")
                .unwrap()
                .timestamp(),
            NaiveDateTime::parse_from_str("2020-02-29 22:55:45", "%Y-%m-%d %H:%M:%S")
                .unwrap()
                .timestamp(),
            NaiveDateTime::parse_from_str("2020-03-30 05:12:45", "%Y-%m-%d %H:%M:%S")
                .unwrap()
                .timestamp(),
            NaiveDateTime::parse_from_str("2020-04-01 09:59:45", "%Y-%m-%d %H:%M:%S")
                .unwrap()
                .timestamp(),
            NaiveDateTime::parse_from_str("2020-05-15 19:01:45", "%Y-%m-%d %H:%M:%S")
                .unwrap()
                .timestamp(),
        ])),
        Arc::new(BooleanArray::from(vec![true, false, true, false, true])),
        Arc::new(dict_array),
    ];

    // Arrow schema created using `Field`
    let schema = Schema::new(vec![
        Field::new("a", DataType::Int32, false),
        Field::new("b", DataType::Int64, false),
        Field::new("c", DataType::Float64, false),
        Field::new("d", DataType::Date32(DateUnit::Day), false),
        Field::new("e", DataType::Timestamp(TimeUnit::Millisecond, None), false),
        Field::new("f", DataType::Boolean, false),
        Field::new(
            "g",
            DataType::Dictionary(Box::new(DataType::Int32), Box::new(DataType::Utf8)),
            false,
        ),
    ]);

    let schema_ref = SchemaRef::new(schema);

    let try_batch = RecordBatch::try_new(schema_ref.clone(), arrays);

    // Accessor schema of names to `DataType`
    let mut accessor_schema: HashMap<String, DataType> = HashMap::new();

    for field in schema_ref.fields() {
        accessor_schema.insert(field.name().clone(), field.data_type().clone());
    }

    match try_batch {
        Ok(batch) => {
            let accessor =
                arrow_accessor::accessor::ArrowAccessor::new(Box::new(batch), schema_ref.clone());

            // Metadata should be correct
            assert_eq!(accessor.column_names, vec!("a", "b", "c", "d", "e", "f", "g"));
            assert_eq!(accessor.schema, accessor_schema);

            // Get values from each column in the accessor
            assert_eq!(accessor.get_i32("a", 1), Some(2));
            assert_eq!(accessor.get_i64("b", 4), Some(5));
            assert_eq!(accessor.get_f64("c", 3), Some(4.5));
            assert_eq!(
                accessor.get_date("d", 0),
                Some(NaiveDate::parse_from_str("2019-04-14", "%Y-%m-%d").unwrap())
            );
            assert_eq!(
                accessor.get_datetime("e", 0),
                Some(NaiveDateTime::parse_from_str("2020-01-15 12:30:45", "%Y-%m-%d %H:%M:%S")
                    .unwrap()
                    .timestamp()
                )
            );
            assert_eq!(accessor.get_bool("f", 3), Some(false));
            assert_eq!(accessor.get_string("g", 2), Some(String::from("abc")));

            // Try some invalid row reads
            assert_eq!(accessor.is_valid("a", 123), false);
            assert_eq!(accessor.is_valid("b", 6), false);
            assert_eq!(accessor.is_valid("c", 100), false);
            assert_eq!(accessor.is_valid("d", 10), false);
            assert_eq!(accessor.is_valid("e", 15), false);
            assert_eq!(accessor.is_valid("f", 55), false);
            assert_eq!(accessor.is_valid("g", 100), false);

            // And invalid columns
            assert_eq!(accessor.is_valid("x", 1), false);
            assert_eq!(accessor.is_valid("y", 1), false);
            assert_eq!(accessor.is_valid("cde", 1), false);
            assert_eq!(accessor.is_valid("def", 1), false);
            assert_eq!(accessor.is_valid("efg", 1), false);
            assert_eq!(accessor.is_valid("hijk", 1), false);
            assert_eq!(accessor.is_valid("lmn", 1), false);
        }
        Err(err) => panic!("Failed to create record batch: {}", err),
    }
}

// #[test]
// fn load_arrow_nullable() {
//     let strings = vec!["abc", "def", "abc", "hij", "klm"];
//     let dict_array: DictionaryArray<Int32Type> = strings.into_iter().collect();

//     let arrays: Vec<ArrayRef> = vec![
//         Arc::new(Int32Array::from(vec![1, 2, 3, 4, 5])),
//         Arc::new(Int64Array::from(vec![1, 2, 3, 4, 5])),
//         Arc::new(Float64Array::from(vec![1.5, 2.5, 3.5, 4.5, 5.5])),
//         Arc::new(Date32Array::from(vec![
//             738000, 737000, 736000, 735000, 734000,
//         ])),
//         Arc::new(TimestampMillisecondArray::from(vec![
//             NaiveDateTime::parse_from_str("2020-01-15 12:30:45", "%Y-%m-%d %H:%M:%S")
//                 .unwrap()
//                 .timestamp(),
//             NaiveDateTime::parse_from_str("2020-02-29 22:55:45", "%Y-%m-%d %H:%M:%S")
//                 .unwrap()
//                 .timestamp(),
//             NaiveDateTime::parse_from_str("2020-03-30 05:12:45", "%Y-%m-%d %H:%M:%S")
//                 .unwrap()
//                 .timestamp(),
//             NaiveDateTime::parse_from_str("2020-04-01 09:59:45", "%Y-%m-%d %H:%M:%S")
//                 .unwrap()
//                 .timestamp(),
//             NaiveDateTime::parse_from_str("2020-05-15 19:01:45", "%Y-%m-%d %H:%M:%S")
//                 .unwrap()
//                 .timestamp(),
//         ])),
//         Arc::new(BooleanArray::from(vec![true, false, true, false, true])),
//         Arc::new(dict_array),
//     ];

//     // Arrow schema created using `Field`
//     let schema = Schema::new(vec![
//         Field::new("a", DataType::Int32, false),
//         Field::new("b", DataType::Int64, false),
//         Field::new("c", DataType::Float64, false),
//         Field::new("d", DataType::Date32(DateUnit::Day), false),
//         Field::new("e", DataType::Timestamp(TimeUnit::Millisecond, None), false),
//         Field::new("f", DataType::Boolean, false),
//         Field::new(
//             "g",
//             DataType::Dictionary(Box::new(DataType::Int32), Box::new(DataType::Utf8)),
//             false,
//         ),
//     ]);

//     let schema_ref = SchemaRef::new(schema);

//     let try_batch = RecordBatch::try_new(schema_ref.clone(), arrays);

//     // Accessor schema of names to `DataType`
//     let mut accessor_schema: HashMap<String, DataType> = HashMap::new();

//     for field in schema_ref.fields() {
//         accessor_schema.insert(field.name().clone(), field.data_type().clone());
//     }

//     match try_batch {
//         Ok(batch) => {
//             let accessor =
//                 arrow_accessor::accessor::ArrowAccessor::new(Box::new(batch), schema_ref.clone());
//             assert_eq!(accessor.column_names, vec!("a", "b", "c", "d", "e"));
//             assert_eq!(accessor.schema, accessor_schema);
//         }
//         Err(err) => panic!("Failed to create record batch: {}", err),
//     }
// }
